{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "%matplotlib inline\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification with CIFAR-10 Dataset\n",
    "[CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) is a widely used benchmark dataset for image classifiers. The dataset consists of 10 classes of color images of size $32\\times 32$. Let's build a neural network with **convolutional layers** to classify the images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the dataset\n",
    "- Use `request` to download the tar file from [https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)\n",
    "- Use `tarfile` to extract files\n",
    "- Use `pickle` to load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "filename = \"cifar-10-python.tar.gz\"\n",
    "if not os.path.isfile(filename):\n",
    "    print(\"Downloading CIFAR10 dataset...\")\n",
    "    url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
    "    file = requests.get(url)\n",
    "\n",
    "    print(\"Writing to file\", filename, \"...\")\n",
    "    with open(filename, \"wb\") as f:\n",
    "        f.write(file.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "datapath = \"cifar-10-batches-py/\" \n",
    "if not os.path.isdir(datapath):\n",
    "    print(\"Extracting files...\")\n",
    "    tar = tarfile.open(filename)\n",
    "    tar.extractall()\n",
    "    tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is broken into batches to **prevent** your machine from running **out of memory**. The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load one batch\n",
    "import pickle\n",
    "with open(datapath + \"data_batch_1\", \"rb\") as f:\n",
    "    batch = pickle.load(f, encoding=\"latin1\")\n",
    "    features = batch['data'].reshape([len(batch['data']), 3, 32, 32]).transpose(0, 2, 3, 1)\n",
    "    labels = batch['labels']\n",
    "print(\"feature size:\", features.shape)\n",
    "print(\"label size:\", len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The label data is just a list of 10000 numbers in the range 0-9, which corresponds to each of the 10 classes in CIFAR-10. \n",
    "\n",
    "* **airplane**\n",
    "* **automobile**\n",
    "* **bird**\n",
    "* **cat**\n",
    "* **deer**\n",
    "* **dog**\n",
    "* **frog**\n",
    "* **horse**\n",
    "* **ship**\n",
    "* **truck**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show a sample image\n",
    "sample_id = 243\n",
    "plt.imshow(features[sample_id])\n",
    "label_names = ['airplane', 'automobile', 'bird',\n",
    "            'cat', 'deer', 'dog', 'frog',\n",
    "            'horse', 'ship', 'truck']\n",
    "plt.xlabel(label_names[labels[sample_id]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to reshape into a such form?\n",
    "\n",
    "The row vector (3072) has the exact same number of elements if you calculate 32\\*32\\*3==3072. In order to reshape the row vector, (3072), there are two steps required. The **first** step is involved with using **reshape** function in numpy, and the **second** step is involved with using **transpose** function in numpy as well.\n",
    "\n",
    "By definition from the official web site, **reshape** function gives a new shape to an array without changing its data. Here, the phrase **without changing its data** is an important part. **reshape** operations should be delivered in three more detailed step. The following direction is described in a logical concept. \n",
    "\n",
    "1. divide the row vector (3072) into 3 pieces. Each piece corresponds to the each channels.\n",
    "  - this results in (3 x 1024) dimension of tensor\n",
    "2. divide the resulting tensor from the previous step with 32. 32 here means width of an image.\n",
    "  - this results in (3 x 32 x 32)\n",
    "\n",
    "In order to implement the directions written in logical sense in numpy, **reshape** function should be called in the following arguments, (10000, 3, 32, 32). As you noticed, reshape function doesn't automatically divide further when the third value (32, width) is provided. We need to explicitly specify the value for the last value (32, height)\n",
    "\n",
    "\n",
    "This is not the end of story. Now, the image data is represented as (num_channel, width, height) form. However, **this is not the shape tensorflow and matplotlib are expecting**. They are expecting different shape of (width, height, num_channel) instead. We need to swap the order of each axes, and that is where **transpose** function comes in.\n",
    "\n",
    "The **transpose** function can take a list of axes, and each value specifies where it wants to move around. For example, calling transpose with argument (1, 2, 0) in an numpy array of (num_channel, width, height) will return a new numpy array of (width, height, num_channel).\n",
    "\n",
    "<img src=\"./reshape-transpose.png\" alt=\"Drawing\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all images from batch 1-5\n",
    "train_features = np.empty([0, 32, 32, 3], dtype=np.uint8)\n",
    "train_labels = np.empty([0])\n",
    "for k in range(1, 6):\n",
    "    with open(datapath + \"data_batch_\" + str(k), \"rb\") as f:\n",
    "        batch = pickle.load(f, encoding=\"latin1\")\n",
    "        features = batch[\"data\"].reshape([len(batch['data']), 3, 32, 32]).transpose(0, 2, 3, 1)\n",
    "        labels=batch['labels']\n",
    "        print(\"features shape:\", features.shape)\n",
    "        print(\"labels shape:\", len(labels))\n",
    "        train_features = np.append(train_features, features, axis=0)\n",
    "        train_labels = np.append(train_labels, labels, axis=0)\n",
    "print(\"train_features shape:\", train_features.shape)\n",
    "print(\"train_labels shape:\", train_labels.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the data\n",
    "- Show image statistics\n",
    "- Show sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display stats\n",
    "print('# of Samples: {}\\n'.format(len(train_features)))\n",
    "\n",
    "df = pd.DataFrame(train_labels, columns=['label'])\n",
    "df['class'] = df['label'].apply(lambda x: label_names[int(x)])\n",
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show more images\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_features[i])\n",
    "    plt.xlabel(label_names[np.argmax(train_labels[i])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the data\n",
    "\n",
    "#### Normalization\n",
    "- this simply makes all x values to range between 0 and 1.\n",
    "- y = (x-min) / (max-min)\n",
    "\n",
    "#### One-hot encoding\n",
    "- the model is designed to show the probabilities of an image for each class.\n",
    "- the ground truth label should be transformed to a set of probabilities to match with the model output\n",
    "- for label $k$, set the $k$-th probability to 1, and set all other probabilities to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data\n",
    "def normalize(x):\n",
    "    \"\"\"\n",
    "        argument\n",
    "            - x: input image data in numpy array [32, 32, 3]\n",
    "        return\n",
    "            - normalized x \n",
    "    \"\"\"\n",
    "    min_val = np.min(x)\n",
    "    max_val = np.max(x)\n",
    "    x = (x-min_val) / (max_val-min_val)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode data\n",
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "        argument\n",
    "            - x: a list of labels\n",
    "        return\n",
    "            - one hot encoding matrix (number of labels, number of class)\n",
    "    \"\"\"\n",
    "    encoded = np.zeros((len(x), 10))\n",
    "    \n",
    "    for idx, val in enumerate(x):\n",
    "        encoded[idx][int(val)] = 1\n",
    "    \n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_scaled = normalize(train_features)\n",
    "train_labels_encoded = one_hot_encode(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the preprocessed data with Pickle\n",
    "\n",
    "**Note: test_batch should also be processed in the same manner.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data and save\n",
    "pickle.dump((train_features_scaled, train_labels_encoded),\n",
    "            open(\"CIFAR10_preprocessed.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to retrieve the data\n",
    "train_features, train_labels = pickle.load(\n",
    "    open(\"CIFAR10_preprocessed.p\"), \"rb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build CNN model\n",
    "### Create Convolutional Model\n",
    "\n",
    "The entire model consists of 14 layers in total. In addition to layers below lists what techniques are applied to build the model.\n",
    "\n",
    "1. Convolution with 64 different filters in size of (3x3)\n",
    "2. Max Pooling by 2\n",
    "  - ReLU activation function \n",
    "  - Batch Normalization\n",
    "3. Convolution with 128 different filters in size of (3x3)\n",
    "4. Max Pooling by 2\n",
    "  - ReLU activation function \n",
    "  - Batch Normalization\n",
    "5. Convolution with 256 different filters in size of (3x3)\n",
    "6. Max Pooling by 2\n",
    "  - ReLU activation function \n",
    "  - Batch Normalization\n",
    "7. Convolution with 512 different filters in size of (3x3)\n",
    "8. Max Pooling by 2\n",
    "  - ReLU activation function \n",
    "  - Batch Normalization\n",
    "9. Flattening the 3-D output of the last convolutional operations.\n",
    "10. Fully Connected Layer with 128 units\n",
    "  - Dropout \n",
    "  - Batch Normalization\n",
    "11. Fully Connected Layer with 256 units\n",
    "  - Dropout \n",
    "  - Batch Normalization\n",
    "12. Fully Connected Layer with 512 units\n",
    "  - Dropout \n",
    "  - Batch Normalization\n",
    "13. Fully Connected Layer with 1024 units\n",
    "  - Dropout \n",
    "  - Batch Normalization\n",
    "14. Fully Connected Layer with 10 units (number of image classes)\n",
    "\n",
    "the image below decribes how the conceptual convolving operation differs from the tensorflow implementation when you use [Channel x Width x Height] tensor format. \n",
    "\n",
    "<img src=\"https://adeshpande3.github.io/assets/Cover.png\" alt=\"Drawing\" style=\"width: 1000px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 100\n",
    "num_predictions = 20\n",
    "\n",
    "import os\n",
    "save_dir = os.path.join(os.getcwd(), \"saved_models\")\n",
    "model_name = \"Keras_CIFAR10.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build CNN model\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, (3, 3), padding=\"same\",\n",
    "                              input_shape=features[0].shape,\n",
    "                              activation=tf.nn.relu))\n",
    "model.add(keras.layers.Conv2D(32, (3, 3),\n",
    "                              activation=tf.nn.relu))\n",
    "model.add(keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(keras.layers.Dropout(0.25))\n",
    "\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), padding=\"same\",\n",
    "                              input_shape=features[0].shape,\n",
    "                              activation=tf.nn.relu))\n",
    "model.add(keras.layers.Conv2D(64, (3, 3),\n",
    "                              activation=tf.nn.relu))\n",
    "model.add(keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(keras.layers.Dropout(0.25))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(512, activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(num_classes, activation=tf.nn.softmax))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_features_scaled, train_labels_encoded, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout and Model Regularization\n",
    "For a complicated model like deep neural networks, a major concern on its performance is model overfitting:\n",
    "![underfitting and overfitting](https://cdn-images-1.medium.com/max/1200/1*cdvfzvpkJkUudDEryFtCnA.png)\n",
    "In plain words, overfitting happens when the model is **memorizing** the training data, and become poorly at **generalizing** what they've learned to unseen data. Think about a student who memorized the entire machine learning textbook. He may appear quite knowledgable in machine learning when asked things directly from the book, but there is no way he can perform a machine project on a dataset not mentioned in the book.\n",
    "\n",
    "### How to dentify model overfitting?\n",
    "- Visualize the model (decision boundary, regression curves, etc.)\n",
    "- Observe the trends in training loss and the testing loss\n",
    "![](https://cdn-images-1.medium.com/max/1600/1*vuZxFMi5fODz2OEcpG-S1g.png)\n",
    "\n",
    "### How to prevent model overfitting?\n",
    "1. Start with a simple model\n",
    "![](https://image.slidesharecdn.com/lawsofwebdesign-091104020153-phpapp01/95/laws-of-web-development-11-728.jpg?cb=1257384621)\n",
    "2. Add penalty to complicated models\n",
    "    - L1 Regularizor\n",
    "    - L2 Regularizor\n",
    "    - Elastic Net\n",
    "\n",
    "3. (For Neural Networks) Dropout layers: remove weights to the next layer\n",
    "![](https://cdn-images-1.medium.com/max/1800/1*iWQzxhVlvadk6VAJjsgXgg.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(valid_features, valid_labels, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
